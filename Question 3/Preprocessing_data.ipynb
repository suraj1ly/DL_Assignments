{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import warnings \n",
    "import json\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import retinanet.model as retinanet_model\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://github.com/qqadssp/RetinaNet-Pytorch/blob/master/utils/utils.py\n",
    "def box_iou(box1, box2, order='xyxy'):\n",
    "    '''Compute the intersection over union of two set of boxes.\n",
    "    The default box order is (xmin, ymin, xmax, ymax).\n",
    "    Args:\n",
    "      box1: (tensor) bounding boxes, sized [N,4].\n",
    "      box2: (tensor) bounding boxes, sized [M,4].\n",
    "      order: (str) box order, either 'xyxy' or 'xywh'.\n",
    "    Return:\n",
    "      (tensor) iou, sized [N,M].\n",
    "    Reference:\n",
    "      https://github.com/chainer/chainercv/blob/master/chainercv/utils/bbox/bbox_iou.py\n",
    "    '''\n",
    "    if order == 'xywh':\n",
    "        box1 = change_box_order(box1, 'xywh2xyxy')\n",
    "        box2 = change_box_order(box2, 'xywh2xyxy')\n",
    "\n",
    "    N = box1.size(0)\n",
    "    M = box2.size(0)\n",
    "\n",
    "    lt = torch.max(box1[:,None,:2], box2[:,:2])  # [N,M,2]\n",
    "    rb = torch.min(box1[:,None,2:], box2[:,2:])  # [N,M,2]\n",
    "\n",
    "    wh = (rb-lt+1).clamp(min=0)      # [N,M,2]\n",
    "    inter = wh[:,:,0] * wh[:,:,1]  # [N,M]\n",
    "\n",
    "    area1 = (box1[:,2]-box1[:,0]+1) * (box1[:,3]-box1[:,1]+1)  # [N,]\n",
    "    area2 = (box2[:,2]-box2[:,0]+1) * (box2[:,3]-box2[:,1]+1)  # [M,]\n",
    "    iou = inter / (area1[:,None] + area2 - inter)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(trainloader,epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    counter = 0\n",
    "    for batch_idx, (inputs, targets,bbox) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net([inputs,bbox])\n",
    "        counter = counter + 1\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation of Parameters\n",
    "epoch_train = 15\n",
    "dropout = 0.2\n",
    "learning_rate = 0.001 \n",
    "momentum = 0.9\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"../train_annotations.json\",\"r\")\n",
    "g = f.read()\n",
    "annotations_dict = json.loads(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.DataFrame(annotations_dict['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(annotations,address):\n",
    "    return np.array(annotations)[list(np.array(annotations['image_id'])).index(address)][2]\n",
    "\n",
    "def mapping(list):\n",
    "    labels = [i for i in range(len(list))]\n",
    "    dict_labels = {}\n",
    "    for i in range(len(labels)):\n",
    "        dict_labels[list[i]] = labels[i]\n",
    "    return dict_labels,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.listdir(\"./train/cat/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(\"./train/cat/\"+f[0],1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_class = os.listdir('./train')\n",
    "dict_labels,labels = mapping(list_class)\n",
    "dataset = []\n",
    "class_ = []\n",
    "bbox = []\n",
    "label_main = []\n",
    "paths = []\n",
    "class_name = []\n",
    "counter_except = 0\n",
    "count_label = []\n",
    "for i in range(len(list_class)):\n",
    "    list_classwise = os.listdir('./train/'+list_class[i])\n",
    "    count_label.append(len(list_classwise))\n",
    "    for j in list_classwise:\n",
    "        img = cv2.imread(\"./train/\"+list_class[i]+\"/\"+j,1)\n",
    "        try:\n",
    "            box = get_bbox(annotations,j.split('.')[0])\n",
    "            bbox.append(box)\n",
    "            img = cv2.resize(img,(100,100))\n",
    "            img = np.swapaxes(img,0,2).flatten()\n",
    "            \n",
    "            paths.append(\"./train/\"+list_class[i]+\"/\"+j)\n",
    "            class_name.append(list_class[i])\n",
    "            label_main.append(dict_labels[list_class[i]])\n",
    "            dataset.append(img)\n",
    "            class_.append(i)\n",
    "        except:\n",
    "            counter_except = counter_except +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_label = []\n",
    "for i in range(len(list_class)):\n",
    "    list_classwise = os.listdir('./train/'+list_class[i])\n",
    "    count_label.append(len(list_classwise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(len(count_label))]\n",
    "plt.pie(count_label, labels=labels, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, label_main,bbox,class_name,paths = shuffle(dataset,label_main,bbox,class_name,paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example format path/to/image.jpg,x1,y1,x2,y2,class_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"class_detail.csv\",\"w\")\n",
    "for i in dict_labels.keys():\n",
    "    f = open(\"class_detail.csv\",\"a\")\n",
    "    f.write(i)\n",
    "    f.write(\",\")\n",
    "    f.write(str(dict_labels[i]))\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the csv file \n",
    "f = open(\"mytraindataset.csv\",\"w\")\n",
    "for i in range(len(paths[:1500])):\n",
    "    f = open(\"mytraindataset.csv\",\"a\")\n",
    "    f.write(paths[i])\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(str(int(bbox[i][0])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(str(int(bbox[i][1])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(str(int(bbox[i][0])+int(bbox[i][3])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        \n",
    "        f.write(str(int(bbox[i][1]) + int(bbox[i][2])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "#     for j in range(len(bbox[i])):\n",
    "#         try:\n",
    "#             f.write(str(int(bbox[i][j])))\n",
    "#             f.write(\",\")\n",
    "#         except:\n",
    "#             f.write(\",\")\n",
    "    f.write(class_name[i])\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "# Making the csv file \n",
    "f = open(\"myvaliddataset.csv\",\"w\")\n",
    "for i in range(len(paths[1500:])):\n",
    "    f = open(\"myvaliddataset.csv\",\"a\")\n",
    "    f.write(paths[i])\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(str(int(bbox[i][0])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(str(int(bbox[i][1])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        f.write(str(int(bbox[i][0])+int(bbox[i][3])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "    try:\n",
    "        \n",
    "        f.write(str(int(bbox[i][1]) + int(bbox[i][2])))\n",
    "    except:\n",
    "        pass\n",
    "    f.write(\",\")\n",
    "    \n",
    "    f.write(class_name[i])\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sample visualization\n",
    "img = dataset[3].reshape(3,256,480)\n",
    "img = np.swapaxes(img,0,2)\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here training\n",
    "train_size = 1500\n",
    "dataset, label_main,bbox = shuffle(dataset,label_main,bbox)\n",
    "tensor_X = torch.stack([torch.from_numpy(i) for i in dataset])\n",
    "tensor_ = torch.stack([torch.from_numpy(np.array(i)) for i in label_main])\n",
    "tensor_label =  torch.stack([torch.from_numpy(np.array(i)).double() for i in bbox])\n",
    "X_train = tensor_X[:train_size]\n",
    "class_train = tensor_[:train_size]\n",
    "X_test = tensor_X[train_size:]\n",
    "class_test = tensor_[train_size:]\n",
    "class_train2 = tensor_label[:train_size]\n",
    "class_test2 = tensor_label[train_size:]\n",
    "train_data = torch.utils.data.TensorDataset(X_train, class_train,class_train2)\n",
    "train_indices = np.arange(len(train_data))\n",
    "np.random.shuffle(train_indices.tolist())\n",
    "train_sample = SubsetRandomSampler(train_indices)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sample, num_workers=0)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, class_test,class_test2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the checkpoint \n",
    "num_classes = 8\n",
    "PATH_TO_WEIGHTS = \"../pretrained_weights.pt\"\n",
    "net = retinanet_model.resnet50(80)\n",
    "checkpoint = torch.load(PATH_TO_WEIGHTS)\n",
    "net.load_state_dict(checkpoint)\n",
    "net.classificationModel.fc = nn.Linear(720, 8)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, start_epoch+200):\n",
    "    train(trainloader,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(dataset_main,label_main,title,classes):\n",
    "    #TSNE Plot for glass dataset\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=10, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(dataset_main)\n",
    "\n",
    "    df_subset = pd.DataFrame()\n",
    "    df_subset['X'] = tsne_results[:,0]\n",
    "    df_subset['y']=label_main\n",
    "    df_subset['Y'] = tsne_results[:,1]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title(title)\n",
    "    sns.scatterplot(\n",
    "        x=\"X\", y=\"Y\",\n",
    "        hue=\"y\",\n",
    "        palette=sns.color_palette(\"hls\", classes),\n",
    "        data=df_subset,\n",
    "        legend=\"full\",\n",
    "        alpha=1.0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(dataset,label_main,\"TSNE Plot for MS Coco\",8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = np.load(\"./epoch_loss1.npy\",allow_pickle=True)\n",
    "reg_loss = np.load(\"./epoch_regloss.npy\",allow_pickle=True)\n",
    "total_loss = np.load(\"epoch_totalloss.npy\",allow_pickle=True)\n",
    "class_loss = np.load(\"epoch_classloss.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = [i for i in range(len(reg_loss))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteration,reg_loss,label=\"Regression\")\n",
    "plt.plot(iteration,total_loss,label=\"Total Loss\")\n",
    "plt.plot(iteration,class_loss,label=\"Classification Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss \")\n",
    "plt.title(\"Loss Vs Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
