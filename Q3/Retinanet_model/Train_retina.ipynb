{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from retinanet import model\n",
    "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter,Normalizer\n",
    "from torch.utils.data import DataLoader\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import warnings \n",
    "import json\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import retinanet.model as retinanet_model\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "assert torch.__version__.split('.')[0] == '1'\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val = CSVDataset(train_file=\"./myvaliddataset.csv\", class_list=\"./class_detail.csv\",\n",
    "#                                  transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "# sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=4,drop_last=False)\n",
    "# dataloader_val = DataLoader(dataset_val, num_workers=3, collate_fn=collater, batch_sampler=sampler_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet = torch.load(\"../pretrained_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CSVDataset(train_file=\"./mytraindataset.csv\", class_list=\"./class_detail.csv\",\n",
    "                               transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "dataset_val = CSVDataset(train_file=\"./myvaliddataset.csv\", class_list=\"./class_detail.csv\",\n",
    "                                 transform=transforms.Compose([Normalizer(), Resizer()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = AspectRatioBasedSampler(dataset_train, batch_size=16, drop_last=False)\n",
    "dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)\n",
    "\n",
    "if dataset_val is not None:\n",
    "    sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=16, drop_last=False)\n",
    "    dataloader_val = DataLoader(dataset_val, num_workers=3, collate_fn=collater, batch_sampler=sampler_val)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "# retinanet = model.resnet50(num_classes=dataset_train.num_classes())\n",
    "use_gpu = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the checkpoint \n",
    "num_classes = 8\n",
    "PATH_TO_WEIGHTS = \"../pretrained_weights.pt\"\n",
    "retinanet = retinanet_model.resnet50(80)\n",
    "checkpoint = torch.load(PATH_TO_WEIGHTS)\n",
    "retinanet.load_state_dict(checkpoint)\n",
    "\n",
    "# retinanet.eval()\n",
    "# for params in retinanet.parameters():\n",
    "#     params.requires_grad = False\n",
    "    \n",
    "retinanet.training = True\n",
    "# retinanet.classificationModel.fc = nn.Linear(720, num_classes)\n",
    "# retinanet.classificationModel.fc.sig = nn.Softmax()\n",
    "# retinanet.classificationModel.fc.requires_grad = True\n",
    "if use_gpu:\n",
    "    retinanet = retinanet.cuda()\n",
    "# print(\"Model retinanet : \",retinanet)\n",
    "retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
    "# optimizer = optim.Adam(filter(lambda p: p.requires_grad, retinanet.parameters()), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "loss_hist = collections.deque(maxlen=500)\n",
    "retinanet.module.freeze_bn()\n",
    "print('Num training images: {}'.format(len(dataset_train)))\n",
    "\n",
    "for epoch_num in range(epochs):\n",
    "\n",
    "    retinanet.train()\n",
    "    retinanet.module.freeze_bn()\n",
    "    epoch_loss = []\n",
    "    for iter_num, data in enumerate(dataloader_train):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot']])\n",
    "\n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "            \n",
    "            loss = classification_loss + regression_loss\n",
    "            \n",
    "            if bool(loss == 0):\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "\n",
    "            optimizer.step()\n",
    "            loss_hist.append(float(loss))\n",
    "\n",
    "            epoch_loss.append(float(loss))\n",
    "\n",
    "            print(\n",
    "                'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
    "                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
    "\n",
    "            del classification_loss\n",
    "            del regression_loss\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    print(\"Done with \",str(epoch_num+1))\n",
    "    if epoch_num%5==0:\n",
    "        print(\"Evaluating dataset............\")\n",
    "        mAP = csv_eval.evaluate(dataset_val, retinanet)\n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "    torch.save(retinanet.module, '{}_retinanet_{}.pt'.format(\"dataset_coco\", epoch_num))\n",
    "    torch.save(retinanet, 'model_final_withoutfinetune_main.pt')\n",
    "\n",
    "retinanet.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
