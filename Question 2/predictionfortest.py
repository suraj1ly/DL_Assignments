# -*- coding: utf-8 -*-
"""PredictionForTest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z0o-jhAUlFX1_Gpc_mn6I2Yw1qi67jx0
"""

from google.colab import drive
drive.mount('/content/drive')

import scipy.io
import numpy as np
import matplotlib.pyplot as plt
import cv2
from sklearn.metrics import confusion_matrix  
from google.colab.patches import cv2_imshow
import copy

import torch
import torch.nn as nn
import numpy as np
import torch.nn.functional as F
from torch.utils.data.sampler import SubsetRandomSampler
from torch.autograd import Variable
from torchsummary import summary

# path = '/content/drive/My Drive/Colab Notebooks/mt18007_skip_new_dl_a1_ques2.py'

cd '/content/drive/My Drive/Colab Notebooks'

from mt18007_skip_new_dl_a1_ques2 import segnet, conv2DBatchNormRelu, segnetDown1, segnetDown2, segnetDown3, segnetDown4, segnetUp1, segnetUp2, segnetUp4, segnetUp5

patch_size = 16
testData = []
testLab = []

def prepTestingData(DtMat, GtMat):
  num1 = int(DtMat.shape[0]/patch_size)
  num2 = int(DtMat.shape[1]/patch_size)
  for i in range(0, DtMat.shape[2]):
    img = DtMat[:,:,i]
    imgLab = GtMat[:,:,i]

    arr = []
    arrLab = []
    for j in range(0, num1):
        arr.append(img[j*patch_size:(j*patch_size)+patch_size,:])
        arrLab.append(imgLab[j*patch_size:(j*patch_size)+patch_size,:])
    arr = np.array(arr)
    arrLab = np.array(arrLab)

    for j in range(0, len(arr)):
      for k in range(0, num2):
        patch = arr[j][:,k*patch_size:(k*patch_size)+patch_size]
        uniq = np.unique(patch)
        if len(uniq) != 1 or uniq[0] != 0:
          patch = np.reshape(patch, (1, patch_size, patch_size))
          patchLab = arrLab[j][:,k*patch_size:(k*patch_size)+patch_size]

          testData.append(patch)
          testLab.append(patchLab)

def predictProb(DataLoader, modelPath):

  SegmentationNet = segnet()
  checkpoint = torch.load(modelPath)
  SegmentationNet.load_state_dict(checkpoint)
  if torch.cuda.is_available():
    SegmentationNet.cuda()

  imgArr = []
  lblArr = []
  out = []
  with torch.no_grad():
      for data in DataLoader:
          images, labels = data

          imageNp = images.numpy()
          labelNp = labels.numpy()
          for i in range(0, imageNp.shape[0]):
            imgArr.append(imageNp[i])
            lblArr.append(labelNp[i])

          if torch.cuda.is_available():
            images = images.cuda().float()
            labels = labels.cuda()

          outputs, soft_output = SegmentationNet(images)

          soft_output = soft_output.cpu().numpy()
          for i in range(0, soft_output.shape[0]):
            out.append(soft_output[i])

  out = np.array(out)
  imgArr = np.array(imgArr)
  lblArr = np.array(lblArr)
  return out, imgArr, lblArr

def predictImage(probMat, flag):
  # flag = 1 for training and 0 for testing

  predictions = []
  for i in range(0, probMat.shape[0]):
    new_img = np.zeros(shape=(patch_size, patch_size))
    for j in range(0, patch_size):
      for k in range(0, patch_size):
        ls = [probMat[i][0][j][k], probMat[i][1][j][k], probMat[i][2][j][k]]
        ind = np.argmax(ls)
        if flag == 0:
          new_img[j][k] = ind + 1
        else:
          new_img[j][k] = ind
    predictions.append(new_img)
  
  predictions = np.array(predictions)
  return predictions

def cm(prediction, actual, flag):
  # flag = 1 for training and 0 for testing

  confMat = np.zeros(shape=(3,3))
  for i in range(0, prediction.shape[0]):
    pred = prediction[i].flatten()
    true = actual[i].flatten()
    
    # vals, cnt = np.unique(pred, return_counts=True)
    # valsTr, cntTr = np.unique(true, return_counts=True)
    cm = np.zeros(shape=(3,3))
    for i in range(0, len(pred)):
        if flag == 0:
          if true[i] != 0:
            cm[int(true[i]-1)][int(pred[i]-1)] = cm[int(true[i]-1)][int(pred[i]-1)] + 1
        else:
          cm[int(true[i])][int(pred[i])] = cm[int(true[i])][int(pred[i])] + 1

    confMat += cm
    
  return confMat

#https://stackoverflow.com/questions/31653576/how-to-calculate-the-mean-iu-score-in-image-segmentation
def compute_iou_dice_acc(confMat):
  intersection = np.diag(confMat)
  ground_truth_set = np.sum(confMat, axis=1)
  predicted_set = np.sum(confMat, axis=0)
  union = ground_truth_set + predicted_set - intersection
  IoU = intersection / union.astype(np.float32)

  dice = []
  for i in range(0, len(IoU)):
    dice.append((2*IoU[i])/(1+IoU[i]))

  clsAcc = []
  for i in range(0, len(ground_truth_set)):
    clsAcc.append(intersection[i]/ground_truth_set[i])

  wt = ground_truth_set/np.sum(confMat)

  acc = np.sum(np.multiply(clsAcc, wt))

  return IoU, np.mean(IoU), dice, np.mean(dice), clsAcc, acc

def evalTest(testDtPth, testLbPth, modelPth):
  matTest = scipy.io.loadmat(testDtPth)
  matGTTest = scipy.io.loadmat(testLbPth)

  prepTestingData(matTest['ana'], matGTTest['gt'])

  tensor_test = torch.stack([torch.from_numpy(i) for i in testData])
  tensorTestLab = torch.stack([torch.from_numpy(i) for i in testLab])

  test_data = torch.utils.data.TensorDataset(tensor_test, tensorTestLab)
  testloader = torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=False, num_workers=0)

  outProbTest, testImages, testLabels = predictProb(testloader, modelPth)
  predTest = predictImage(outProbTest, 0)

  confMatTest = cm(predTest, testLabels, 0)
  IouClsVal, IouVal, diceClsVal, diceVal, accClsVal, accVal = compute_iou_dice_acc(confMatTest) 

  return diceClsVal, diceVal, accClsVal, accVal

testDtPth = '/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/validation/Vol_06_input.mat'
testLbPth = '/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/validation/Vol_06gt.mat'
modelPth = '/content/drive/My Drive/Colab Notebooks/DL_SkipModels_A1Q2_v1/0'

diceCls, dice, accArr, acc = evalTest(testDtPth, testLbPth, modelPth)
print(diceCls, dice, accArr, acc)

