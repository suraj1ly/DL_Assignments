# -*- coding: utf-8 -*-
"""Copy of MT18007_New_DL_A1_Ques2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XnIujOjeRL4pgXF8EJ3h7hSMgY563bd
"""

from google.colab import drive
drive.mount('/content/drive')

import scipy.io
import numpy as np
import matplotlib.pyplot as plt
import cv2
from sklearn.metrics import confusion_matrix  
from google.colab.patches import cv2_imshow
import copy

import torch
import torch.nn as nn
import numpy as np
import torch.nn.functional as F
from torch.utils.data.sampler import SubsetRandomSampler
from torch.autograd import Variable
from torchsummary import summary

mat01 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/training/Vol_01_input.mat')
mat02 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/training/Vol_02_input.mat')
mat03 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/training/Vol_05_input.mat')

matGT01 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/training/Vol_01gt.mat')
matGT02 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/training/Vol_02gt.mat')
matGT03 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/training/Vol_05gt.mat')

matVal = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/validation/Vol_06_input.mat')
matValGT = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/DL/Brain_segmentation_dataset/validation/Vol_06gt.mat')

def prepTrainingData(DtMat, GtMat):
  for i in range(0, GtMat.shape[2]):
    values, cnt = np.unique(GtMat[:,:,i], return_counts=True)
    if (len(values) == 3 and values[0] == 1 and cnt[0]>threshold) or (len(values) == 4 and values[1] == 1 and cnt[1] > threshold):
      img = GtMat[:,:,i]

      for j in range(0, img.shape[0]):
        for k in range(0, img.shape[1]):
          if img[j][k] == 1:
            patch = img[j-size:j+size, k-size:k+size]
            val, count = np.unique(patch, return_counts=True)
            if len(val) == 3 and val[0] == 1 and count[0] > threshold and count[1] > threshold and count[2] > threshold:
              labelImgs.append(patch)
              inpImg = DtMat[j-size:j+size, k-size:k+size, i]
              inpImg = np.reshape(inpImg, (1, patch_size, patch_size))
              inpData.append(inpImg)

def prepTestingData(DtMat, GtMat):
  num1 = int(DtMat.shape[0]/patch_size)
  num2 = int(DtMat.shape[1]/patch_size)
  for i in range(0, DtMat.shape[2]):
    img = DtMat[:,:,i]
    imgLab = GtMat[:,:,i]

    arr = []
    arrLab = []
    for j in range(0, num1):
        arr.append(img[j*patch_size:(j*patch_size)+patch_size,:])
        arrLab.append(imgLab[j*patch_size:(j*patch_size)+patch_size,:])
    arr = np.array(arr)
    arrLab = np.array(arrLab)

    for j in range(0, len(arr)):
      for k in range(0, num2):
        patch = arr[j][:,k*patch_size:(k*patch_size)+patch_size]
        uniq = np.unique(patch)
        if len(uniq) != 1 or uniq[0] != 0:
          patch = np.reshape(patch, (1, patch_size, patch_size))
          patchLab = arrLab[j][:,k*patch_size:(k*patch_size)+patch_size]

          valData.append(patch)
          valLab.append(patchLab)

def predictProb(DataLoader):
  imgArr = []
  lblArr = []
  out = []
  with torch.no_grad():
      for data in DataLoader:
          images, labels = data

          imageNp = images.numpy()
          labelNp = labels.numpy()
          for i in range(0, imageNp.shape[0]):
            imgArr.append(imageNp[i])
            lblArr.append(labelNp[i])

          if torch.cuda.is_available():
            images = images.cuda().float()
            labels = labels.cuda()

          outputs, soft_output = SegmentationNet(images)

          soft_output = soft_output.cpu().numpy()
          for i in range(0, soft_output.shape[0]):
            out.append(soft_output[i])

  out = np.array(out)
  imgArr = np.array(imgArr)
  lblArr = np.array(lblArr)
  return out, imgArr, lblArr

def predictImage(probMat, flag):
  # flag = 1 for training and 0 for testing

  predictions = []
  for i in range(0, probMat.shape[0]):
    new_img = np.zeros(shape=(patch_size, patch_size))
    for j in range(0, patch_size):
      for k in range(0, patch_size):
        ls = [probMat[i][0][j][k], probMat[i][1][j][k], probMat[i][2][j][k]]
        ind = np.argmax(ls)
        if flag == 0:
          new_img[j][k] = ind + 1
        else:
          new_img[j][k] = ind
    predictions.append(new_img)
  
  predictions = np.array(predictions)
  return predictions

def cm(prediction, actual, flag):
  # flag = 1 for training and 0 for testing

  confMat = np.zeros(shape=(3,3))
  for i in range(0, prediction.shape[0]):
    pred = prediction[i].flatten()
    true = actual[i].flatten()
    
    # vals, cnt = np.unique(pred, return_counts=True)
    # valsTr, cntTr = np.unique(true, return_counts=True)
    cm = np.zeros(shape=(3,3))
    for i in range(0, len(pred)):
        if flag == 0:
          if true[i] != 0:
            cm[int(true[i]-1)][int(pred[i]-1)] = cm[int(true[i]-1)][int(pred[i]-1)] + 1
        else:
          cm[int(true[i])][int(pred[i])] = cm[int(true[i])][int(pred[i])] + 1

    confMat += cm
    
  return confMat

def calcWtAcc(confMat):
  ground_truth_set = np.sum(confMat, axis=1)
  intersection = np.diag(confMat)
  clsAcc = []
  for i in range(0, len(ground_truth_set)):
    clsAcc.append(intersection[i]/ground_truth_set[i])

  wt = ground_truth_set/np.sum(confMat)
  
  acc = np.sum(np.multiply(clsAcc, wt))
  return acc

#https://stackoverflow.com/questions/31653576/how-to-calculate-the-mean-iu-score-in-image-segmentation
def compute_iou_dice_acc(confMat):
  intersection = np.diag(confMat)
  ground_truth_set = np.sum(confMat, axis=1)
  predicted_set = np.sum(confMat, axis=0)
  union = ground_truth_set + predicted_set - intersection
  IoU = intersection / union.astype(np.float32)

  dice = []
  for i in range(0, len(IoU)):
    dice.append((2*IoU[i])/(1+IoU[i]))

  clsAcc = []
  for i in range(0, len(ground_truth_set)):
    clsAcc.append(intersection[i]/ground_truth_set[i])

  wt = ground_truth_set/np.sum(confMat)

  acc = np.sum(np.multiply(clsAcc, wt))

  return IoU, np.mean(IoU), dice, np.mean(dice), clsAcc, acc

inpData = []
labelImgs = []

valData = []
valLab = []

patch_size = 16
threshold = 50
size = int(patch_size/2)

prepTrainingData(mat01['ana'], matGT01['gt'])
prepTrainingData(mat02['ana'], matGT02['gt'])
prepTrainingData(mat03['ana'], matGT03['gt'])

prepTestingData(matVal['ana'], matValGT['gt'])

inpData = np.array(inpData)
labelImgs = np.array(labelImgs)
valData = np.array(valData)
valLab = np.array(valLab)

print(inpData.shape, labelImgs.shape, valData.shape, valLab.shape, np.unique(labelImgs), np.unique(valLab))

plt.imshow(labelImgs[9000])
plt.show()

plt.imshow(inpData[9000].reshape(16, 16))
plt.show()

plt.imshow(valLab[3000])
plt.show()

plt.imshow(valData[3000].reshape(16, 16))
plt.show()

tensor_X = torch.stack([torch.from_numpy(i) for i in inpData])
tensor_ = torch.stack([torch.from_numpy(np.array(i-1)) for i in labelImgs])

tensor_val = torch.stack([torch.from_numpy(i) for i in valData])
tensorValLab = torch.stack([torch.from_numpy(i) for i in valLab])

train_data = torch.utils.data.TensorDataset(tensor_X, tensor_)
train_indices = np.arange(len(train_data))
np.random.shuffle(train_indices.tolist())
train_sample = SubsetRandomSampler(train_indices)
trainloader = torch.utils.data.DataLoader(train_data, batch_size=16, sampler=train_sample, num_workers=0)

val_data = torch.utils.data.TensorDataset(tensor_val, tensorValLab)
valloader = torch.utils.data.DataLoader(val_data, batch_size=16, shuffle=False, num_workers=0)

#https://github.com/meetshah1995/pytorch-semseg
class conv2DBatchNormRelu(nn.Module):
    def __init__(self, in_channels, n_filters, k_size, stride, padding, bias=True, dilation=1, is_batchnorm=True,):
        super(conv2DBatchNormRelu, self).__init__()

        conv_mod = nn.Conv2d(int(in_channels), int(n_filters), kernel_size=k_size, padding=padding, stride=stride, bias=bias, dilation=dilation,)

        if is_batchnorm:
            self.cbr_unit = nn.Sequential(conv_mod, nn.BatchNorm2d(int(n_filters)), nn.ReLU(inplace=True), nn.Dropout(p=0.2))
        else:
            self.cbr_unit = nn.Sequential(conv_mod, nn.ReLU(inplace=True), nn.Dropout(p=0.2))

    def forward(self, inputs):
        outputs = self.cbr_unit(inputs)
        return outputs

class segnetDown1(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetDown1, self).__init__()
        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)
        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)

    def forward(self, inputs):
        outputs = self.conv1(inputs)
        outputs = self.conv2(outputs)
        unpooled_shape = outputs.size()
        outputs, indices = self.maxpool_with_argmax(outputs)
        return outputs, indices, unpooled_shape

class segnetDown2(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetDown2, self).__init__()
        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)

    def forward(self, inputs):
        outputs = self.conv1(inputs)
        outputs = self.conv2(outputs)
        return outputs

class segnetDown3(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetDown3, self).__init__()
        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)
        self.conv3 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)
        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)

    def forward(self, inputs):
        outputs = self.conv1(inputs)
        outputs = self.conv2(outputs)
        outputs = self.conv3(outputs)
        unpooled_shape = outputs.size()
        outputs, indices = self.maxpool_with_argmax(outputs)
        return outputs, indices, unpooled_shape

class segnetDown4(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetDown4, self).__init__()
        self.conv1 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)
        self.conv3 = conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)

    def forward(self, inputs):
        outputs = self.conv1(inputs)
        outputs = self.conv2(outputs)
        outputs = self.conv3(outputs)
        return outputs 

class segnetUp1(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetUp1, self).__init__()
        self.unpool = nn.MaxUnpool2d(2, 2)
        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)

    def forward(self, inputs, indices, output_shape):
        # print("up1", inputs.shape, output_shape)
        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)
        # print("up1", outputs.shape)
        outputs = self.conv1(outputs)
        outputs = self.conv2(outputs)
        return outputs


class segnetUp2(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetUp2, self).__init__()
        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)

    def forward(self, inputs):
        outputs = self.conv1(inputs)
        outputs = self.conv2(outputs)
        return outputs

class segnetUp4(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetUp4, self).__init__()
        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)
        self.conv3 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)

    def forward(self, inputs):
        outputs = self.conv1(inputs)
        outputs = self.conv2(outputs)
        outputs = self.conv3(outputs)
        return outputs

class segnetUp5(nn.Module):
    def __init__(self, in_size, out_size):
        super(segnetUp5, self).__init__()
        self.unpool = nn.MaxUnpool2d(2, 2)
        self.conv1 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)
        self.conv2 = conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)
        self.conv3 = conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)

    def forward(self, inputs, indices, output_shape):
        # print("up5", inputs.shape, output_shape)
        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)
        # print("up5", outputs.shape)
        outputs = self.conv1(outputs)
        outputs = self.conv2(outputs)
        outputs = self.conv3(outputs)
        return outputs

class segnet(nn.Module):
    def __init__(self, n_classes=3, in_channels=1, is_unpooling=True):
        super(segnet, self).__init__()

        self.in_channels = in_channels
        self.is_unpooling = is_unpooling

        self.c1 = segnetDown1(self.in_channels, 64)
        self.c2 = segnetDown2(64, 128)
        self.c3 = segnetDown3(128, 256)
        self.c4 = segnetDown4(256, 512)
        self.c5 = segnetDown3(512, 512)

        self.up5 = segnetUp5(512, 512)
        self.up4 = segnetUp4(512, 256)
        self.up3 = segnetUp5(256, 128)
        self.up2 = segnetUp2(128, 64)
        self.up1 = segnetUp1(64, n_classes)

    def forward(self, inputs):

        c1, indices_1, unpool_shape1 = self.c1(inputs)
        c2 = self.c2(c1)
        c3, indices_3, unpool_shape3 = self.c3(c2)
        c4 = self.c4(c3)
        c5, indices_5, unpool_shape5 = self.c5(c4)

        up5 = self.up5(c5, indices_5, unpool_shape5)
        up4 = self.up4(up5)
        up3 = self.up3(up4, indices_3, unpool_shape3)
        up2 = self.up2(up3)
        up1 = self.up1(up2, indices_1, unpool_shape1)

        x_softmax = F.softmax(up1, dim=1)
        return up1, x_softmax

SegmentationNet = segnet()
if torch.cuda.is_available():
  SegmentationNet.cuda()

criterionClf = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(SegmentationNet.parameters(), lr=0.001, weight_decay=1e-5)

# summary(SegmentationNet, (1, 32, 32))

num_epochs = 1
pth = '/content/drive/My Drive/Colab Notebooks/DL_Models_A1Q2_v3/'
k = 0
lossArr = []
accArrTrain = []
accArrVal = []
for epoch in range(0, num_epochs):
  lossPerEpoch = 0

  trainingOut = []
  trainingLab = []
  for i, data in enumerate(trainloader, 0):
    imgs, labels = data
    if torch.cuda.is_available():
        imgs = imgs.cuda().float()
        labels = labels.cuda()

    output, soft_output = SegmentationNet(imgs)

    loss = criterionClf(output, labels.long())
    # print(output.shape, labels.shape)

    lossPerEpoch += loss.item()

    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    soft_output = soft_output.cpu().detach().numpy()
    for j in range(0, soft_output.shape[0]):
      trainingOut.append(soft_output[j])
    labels = labels.cpu().numpy()
    for j in range(0, labels.shape[0]):
      trainingLab.append(labels[j])

  trainingOut = np.array(trainingOut)
  trainingLab = np.array(trainingLab)
  predTrain = predictImage(trainingOut, 1)
  confMatTrain = cm(predTrain, trainingLab, 1)
  TrainAcc = calcWtAcc(confMatTrain)

  torch.save(SegmentationNet.state_dict(), pth+str(k))
  lossValue = lossPerEpoch/len(train_data)

  with torch.no_grad():
    out = []
    for i, data in enumerate(valloader, 0):
      imgs, labels = data
      if torch.cuda.is_available():
          imgs = imgs.cuda().float()
          labels = labels.cuda()
      
      output, soft_output = SegmentationNet(imgs)

      soft_output = soft_output.cpu().detach().numpy()
      for j in range(0, soft_output.shape[0]):
        out.append(soft_output[j])

  out = np.array(out)
  predVal = predictImage(out, 0)
  confMat = cm(predVal, valLab, 0)
  ValidAcc = calcWtAcc(confMat)
  
  print("Epoch ", epoch, ": Training Loss = ", lossValue, "Training Accuracy = ", TrainAcc, " Validation Accuracy = ", ValidAcc)
  lossArr.append(lossValue)
  accArrVal.append(ValidAcc)
  accArrTrain.append(TrainAcc)

  # torch.save(SegmentationNet.state_dict(), pth+str(k))

i = np.argmin(lossArr)
plotLoss = lossArr[0:i+1]
plotTrainAcc = accArrTrain[0:i+1]
plotValAcc = accArrVal[0:i+1]
print(plotLoss, plotTrainAcc, plotValAcc)

# plt.plot([i for i in range(0, len(lossArr))], lossArr, label="Training Loss")
plt.xlabel("Epoch")
plt.plot([i for i in range(0, len(plotLoss))], plotLoss, label="Training Loss")
plt.ylabel("Loss")
plt.title("Loss vs Epochs")
plt.legend()
plt.show()

plt.plot([i for i in range(0, len(plotTrainAcc))], plotTrainAcc, label="Training Accuracy")
plt.plot([i for i in range(0, len(plotValAcc))], plotValAcc, label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy vs Epochs")
plt.legend()
plt.show()

plt.plot([i for i in range(0, len(plotTrainAcc))], plotTrainAcc, label="Training Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy vs Epochs")
plt.legend()
plt.show()

plt.plot([i for i in range(0, len(plotValAcc))], plotValAcc, label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Accuracy vs Epochs")
plt.legend()
plt.show()

outProbTrain, trainImages, trainLabels = predictProb(trainloader)
outProbVal, valImages, valLabels = predictProb(valloader)

print(outProbTrain.shape, trainImages.shape, trainLabels.shape)
print(outProbVal.shape, valImages.shape, valLabels.shape)

freq, count = np.unique(trainLabels, return_counts=True)

uniq, freq = np.unique(valLabels, return_counts=True)
print(uniq, freq)
uniqTr, freqTr = np.unique(trainLabels, return_counts=True)
print(uniqTr, freqTr)

a, b = np.unique(matGT01['gt'], return_counts=True)
c, d = np.unique(matGT02['gt'], return_counts=True)
e, f = np.unique(matGT03['gt'], return_counts=True)
print(a, b)
print(c, d)
print(e, f)

print(freq, count)

predTrain = predictImage(outProbTrain, 1)
predVal = predictImage(outProbVal, 0)

print(predTrain.shape, predVal.shape, np.unique(predTrain), np.unique(predVal))
print(trainLabels.shape, valLabels.shape, np.unique(trainLabels), np.unique(valLabels))
print(trainImages.shape, valImages.shape)

confMatTrain = cm(predTrain, trainLabels, 1)
IouClsTr, IouTr, diceClsTr, diceTr, accClsTr, accTr = compute_iou_dice_acc(confMatTrain) 
print("Training")
print(IouClsTr, IouTr, diceClsTr, diceTr, accClsTr, accTr)

confMatVal = cm(predVal, valLabels, 0)
IouClsVal, IouVal, diceClsVal, diceVal, accClsVal, accVal = compute_iou_dice_acc(confMatVal) 
print("Validation")
print(IouClsVal, IouVal, diceClsVal, diceVal, accClsVal, accVal)

print(confMatTrain, "\n")
print(confMatVal)

def sliceVisualisation(image, imageLabel):
  num1 = int(image.shape[0]/patch_size)
  num2 = int(image.shape[1]/patch_size)
  num_patches = num1 * num2
  patch_array = np.zeros(shape=(num_patches, patch_size, patch_size))  #will store the final patches
  indices = [] #contains the indices for which network will give output 
  dt = [] #contains patches to be passed to model
  dtLab = []
  indVal = 0

  arr = []
  arrLab = []
  for j in range(0, num1):
      arr.append(image[j*patch_size:(j*patch_size)+patch_size,:])
      arrLab.append(imageLabel[j*patch_size:(j*patch_size)+patch_size,:])
  arr = np.array(arr)
  arrLab = np.array(arrLab)

  for j in range(0, len(arr)):
    for k in range(0, num2):
      patch = arr[j][:,k*patch_size:(k*patch_size)+patch_size]
      patchLab = arrLab[j][:,k*patch_size:(k*patch_size)+patch_size]
      uniq = np.unique(patch)
      if len(uniq) != 1 or uniq[0] != 0:
        patch = np.reshape(patch, (1, patch_size, patch_size))
        dt.append(patch)
        dtLab.append(patchLab)
        indices.append(indVal)
      indVal += 1

  dtLab = np.array(dtLab)
  tensor_image = torch.stack([torch.from_numpy(i) for i in dt])
  image_Data = torch.utils.data.TensorDataset(tensor_image)
  ImageLoader = torch.utils.data.DataLoader(image_Data, batch_size=4, shuffle=False, num_workers=0)

  out = []
  with torch.no_grad():
      for idx,data in enumerate(ImageLoader):
          if torch.cuda.is_available():
            data = data[0].cuda().float()
    
          outputs, soft_output = SegmentationNet(data)

          soft_output = soft_output.cpu().numpy()
          for i in range(0, soft_output.shape[0]):
            out.append(soft_output[i])

  out = np.array(out)
  
  predictedPatches = predictImage(out, 0)
  print(predictedPatches.shape, len(indices))
  # print(predictedPatches)

  for i in range(0, len(indices)):
    for j in range(0, predictedPatches.shape[1]):
      for k in range(0, predictedPatches.shape[2]):
        if dtLab[i][j][k] == 0:
          patch_array[indices[i]][j][k] = 0
        else:
          patch_array[indices[i]][j][k] = predictedPatches[i][j][k]
    # patch_array[indices[i]] = predictedPatches[i]


  # recons = []
  # for i in range(0, num1):
  #   temp = []
  #   for j in range(0, num2):
  #       temp.append(patch_array[(i*num2) + j])
  #   temp = np.array(temp)
  #   recons.append(temp)
  
  # recons = np.array(recons)
  # recons = np.array(np.reshape(recons, (image.shape[0], image.shape[1])), dtype=float)
  return predictedPatches, dtLab, patch_array

visInd = 129
Pred, actual, patchArray = sliceVisualisation(mat01['ana'][:,:,visInd], matGT01['gt'][:,:,visInd])
print(Pred.shape, actual.shape)
showVis = patchArray.reshape(16,8,16,16).swapaxes(1,2).reshape(256,128)
plt.imshow(showVis)

plt.imshow(mat01['ana'][:,:,visInd])

plt.imshow(matValGT['gt'][:,:,visInd])

# print(patchArray.shape)
# w=10
# h=10
# fig=plt.figure(figsize=(16, 8))
# columns = 8
# rows = 16
# for i in range(1, columns*rows +1):
#     img = patchArray[i-1]
#     fig.add_subplot(rows, columns, i)
#     plt.imshow(img)
# plt.show()

testind = 3189

# plt.imshow(trainingImages[testind].reshape(16, 16))
plt.imshow(trainImages[testind].reshape(16, 16))

plt.imshow(trainLabels[testind])

plt.imshow(predTrain[testind])

plt.imshow(valImages[testind].reshape(16, 16))

plt.imshow(valLabels[testind])

plt.imshow(predVal[testind])

plt.imshow(mat01['ana'][:,:,195])

plt.imshow(mat02['ana'][:,:,205])

plt.imshow(mat03['ana'][:,:,195])

plt.imshow(matGT01['gt'][:,:, 195])
plt.show()

plt.imshow(matGT02['gt'][:,:, 205])
plt.show()

plt.imshow(matGT03['gt'][:,:,195])
plt.show()

(plt.imshow(inp[780])
plt.show()

plt.imshow(lab[780])
plt.show()

plt.imshow(mat01['ana'][:,:,130])
plt.show()

plt.imshow(mat02['ana'][:,:,150])
plt.show()

plt.imshow(mat03['ana'][:,:,150])
plt.show()

